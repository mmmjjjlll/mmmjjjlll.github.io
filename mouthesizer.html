<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=us-ascii"><meta name="Keywords" content="MIDI Controllers, Computer Music, Facial Action,
Musical Interfaces, Lyons, Michael Lyons, Michael J. Lyons">
	<title>The Mouthesizer</title>
</head>
<body alink="#ff0000" bgcolor="#ffffff" link="#0000ee" text="#000000" vlink="#ff0000">
<center>
<h2><font face="gillsans,helvetica,arial">The Mouthesizer </font></h2>
<font face="gillsans,helvetica,arial">With the Mouthesizer, a mini headmounted ccd camera tracks the shadow area inside the mouth using colour and intensity thresholding. Shape parameters extracted from the segmented region are mapped to MIDI control changes. This allows one to control audio effects, synthesizer parameters, or anything you like with movements of the mouth. The vision algorithm is stable because the mouth opening is not a surface: illumination variations do not have a large effect on the segmented area.<br />
<br />
<img src="vowels.jpg" /> <img src="mouth.jpg" /> </font>

<h3><font face="gillsans,helvetica,arial">Video Clips </font></h3>
	<font face="gillsans,helvetica,arial">
		<a href="http://www.kasrl.org/Hypnotic.mpg"> <img src="hypnotic_thumb.jpg" /></a> 
		<a href="http://www.kasrl.org/Vowel.mpg"> <img src="vowel_thumb.jpg" /></a> 
		<a href="https://youtu.be/1I5v_Rtjgso?si=UtV6PhSh262rHPb1"> <img src="umata_thumb.jpg" /></a> 
	</font>

<h3><font face="gillsans,helvetica,arial">Gesture-Sound Mapping Descriptions </font></h3>
<font face="gillsans,helvetica,arial">In the first two video clips the mouthesizer controls timbre parameters in two sequencer loops implemented on the Nord Mod virtual modular synthesizer (made by Clavia, Sweden). In the <b>first clip</b>, mouth width is mapped to resonance and mouth height to the cut-off frequency of a low-pass filter. The mapping is non-linear, as becomes evident when the tongue is brought into play. In the <b>second clip</b> the aspect ratio of the segmented area is used to control a morph between the vowel formant filters for the vowels [a], [i], [o]. The mapping is chosen to correspond with the actual acoustic shape to sound mapping in speech production. This gives the player an intuitive gesture to effect mapping which makes use of existing human capabilities for sound control. In the <b>third video clip</b>, jazz guitarist Ichiro Umata uses the mouthesizer to control wah-wah and distortion. The height of the mouth opening is mapped to the cutoff frequency of a low pass filter, so that opening and closing the mouth gives a wah-wah effect (voicing &quot;ah&quot; and opening and closing the mouth has a similar acoustic effect). Mouth width is mapped to distortion: stretching the corners of the mouth wide in an emotional grimace produces a gritty, distorted sound. Like a foot pedal, the mouthesizer offers an additional controller to a musician who has both hands busy with a musical instrument. Our studies suggest that the mouth controller is more intuitive and easier to learn than a foot pedal. </font><br />
&nbsp;
<h3><font face="gillsans,helvetica,arial">Live Performance </font></h3>
<a href="http://www.kasrl.org/kyoryukan.html"><font face="gillsans,helvetica,arial"> <img alt="jordan_thumb.jpg" src="jordan_thumb.jpg" style="border: 2px solid ; width: 180px; height: 182px;" /> </font></a>

<h3><font face="gillsans,helvetica,arial">Why? </font></h3>
<font face="gillsans,helvetica,arial">The musculature of the face allows for fine motor control of actions, and the associated cortical circuitry occupies a comparatively large part of the somatosensory area. So it is interesting to explore the possibility of machine interfaces that are driven by facial action. Because facial action is involved in both speech production and emotional expression, there is a rich space of intuitive gesture to sound mappings for face action. These thoughts motivated our current exploration of facial gesture musical interfaces. It would be interesting to develop a facial gesture music interface for quadriplegic djs to allow them to control the expressive part of techno loops, for example. Spinal paralysis usually leaves cranial nerves, and facial control, intact.</font><br />
&nbsp;
<h3><font face="gillsans,helvetica,arial">More Info: Publications </font></h3>
<font face="gillsans,helvetica,arial"><i>Facing the Music: A Facial Action Controlled Musical Interface</i><br />
Michael J. Lyons &amp; Nobuji Tetsutani<br />
Proceedings, CHI 2001, Conference on Human Factors in Computing Systems<br />
March 31 - April 5, Seattle, pp. 309-310. <a href="http://www.kasrl.org/Lyons_chi2001.pdf">(150K PDF)</a><br />
<br />
<i>The Mouthesizer: A Facial Gesture Musical Interface</i><br />
Michael J. Lyons, Michael Haehnel &amp; Nobuji Tetsutani<br />
Conference Abstracts, Siggraph 2001, Los Angeles, p. 230. <a href="http://www.kasrl.org/79.pdf">(234K PDF)</a></font>

<h3><font face="gillsans,helvetica,arial">Media Coverage </font></h3>
<font face="gillsans,helvetica,arial">Magazine: <a href="http://www.newscientist.com/hottopics/tech/wahwah.jsp">NewScientist</a>, <a href="http://www.asiaweek.com/asiaweek/magazine/ThreeSixty/0,8782,174681,00.html">AsiaWeek,</a> <a href="http://www.computerra.ru/offline/2001/409/12145/">Computerra </a>(Russian), <a href="http://www.trends.be/CdicsArticles/ShowArticleZoek.asp?ngratis=ja&amp;show=TR/TR0140/IDEE40QQ_407.xml">Trends </a>(Flemish)<br />
Newspaper: <a href="http://www.hindustantimes.com/nonfram/070901/HTS03.asp">Hindustan Times</a><br />
Radio: <a href="http://www.theworld.org/technology.htm">Public Radio International&#39;s World Technology Report</a><br />
Web: <a href="http://www.ing.dk/konf/root/redproduktion/sub/noter/html/4360.html">Ingenioren|net</a> (Danish), <a href="http://idlive1.astaga.com/smart/artikel.php?article_id=74586">Astaga!com</a> (Indonesian), <a href="http://www.canalkids.com.br/central/arquivo/tec_pedal.htm">Jornal do Canal</a> (Portugese), <a href="http://hotwired.lycos.com/webmonkey/frontdoor/monkey_bite/01aug_index.html">Hotwired Webmonkey</a>, <a href="http://www.silkhouse.co.uk/tytv/html/didyouknow/archive/music/musicnov.shtm"> Silkhouse.co.uk </a><a> </a></font>

<h3><font face="gillsans,helvetica,arial"><a>Other Research Projects on this Site: </a></font></h3>
<font face="gillsans,helvetica,arial"><a href="http://www.kasrl.org/noh_mask.html">The Noh Mask Effect</a><br />
<a href="https://zenodo.org/record/3451524">JAFFE Facial Expression Database</a><br />
<a href="http://www.kasrl.org/avatar.html">Personalized Avatar Creation using Face Recognition</a><br />
<a href="http://www.kasrl.org/facial_expression.html">Web Resources on Facial Expression Research</a></font>

<h3><font face="gillsans,helvetica,arial">ACM CHI&#39;2006 Workshop on <a href="http://www.bartneck.de/workshop/chi2006/index.html">HCI and the Face</a> </font></h3>
&nbsp;

<center><font face="gillsans,helvetica,arial"><b><a href="http://www.kasrl.org/michael.lyons.html">Home</a></b></font></center>
</center>
</body>
</html>
